"""
Параметры генерации текста для языковой модели

Настройки влияют на качество и разнообразие генерируемого текста:
- do_sample: Включение вероятностного семплирования
- max_length: Максимальная общая длина текста (промпт + ответ)
- max_new_tokens: Максимальная длина генерируемого ответа
- temperature: Уровень случайности (0.1-1.0)
- top_p: Диапазон слов, из которых модель выбирает ответ
- top_k: Ограничение выбора топ-k токенов
- repetition_penalty: Подавление повторяющихся фраз
"""

do_sample = True
max_length = 2048
max_new_tokens = 2048
temperature = 0.7
top_p = 0.9
top_k = 50
repetition_penalty = 1.1
